{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create all the models we are going to use\n",
    "\n",
    "Most of them aren't going to work particularly well. But, we are gonna build all the frameworks out, so as we update things, we can just rerun this notebook to get better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boada/.local/lib/python3.7/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "/home/boada/.local/lib/python3.7/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# basic stuff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# sklearn for logreg, RF, GBT, and SVM\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# other stuff from sklearn we might need\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.utils import resample # we have imbalanced classes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# keras for the NN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Stuff that I wrote\n",
    "from utils.strings import TARGET, FEATURES, CAT_FEATURES, DATE\n",
    "from utils.utilities import select_by_date\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the data\n",
    "\n",
    "we also need to do some simple preprocessing (for now) before we can train all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 111854 entries, 0 to 111853\n",
      "Data columns (total 29 columns):\n",
      "camis                    111854 non-null int64\n",
      "dba                      111854 non-null object\n",
      "boro                     111854 non-null object\n",
      "zipcode                  111854 non-null float64\n",
      "cuisine_description      111854 non-null object\n",
      "inspection_date          111854 non-null datetime64[ns]\n",
      "action                   111854 non-null object\n",
      "score                    111854 non-null float64\n",
      "latitude                 111854 non-null float64\n",
      "longitude                111854 non-null float64\n",
      "grade                    111854 non-null object\n",
      "violation_code           111854 non-null object\n",
      "violation_description    111854 non-null object\n",
      "critical_flag            111854 non-null object\n",
      "inspection_type          111854 non-null object\n",
      "critical                 111854 non-null int64\n",
      "num_critical             111854 non-null int64\n",
      "weekday                  111854 non-null object\n",
      "tmax                     111854 non-null int64\n",
      "tmax_3d                  111854 non-null float64\n",
      "time_since_last          111854 non-null float64\n",
      "past_critical            111854 non-null float64\n",
      "past_grade               111854 non-null object\n",
      "past_score               111854 non-null float64\n",
      "dsny_heat_score          111854 non-null float64\n",
      "dep_heat_score           111854 non-null float64\n",
      "dohmh_heat_score         111854 non-null float64\n",
      "is_chain                 111854 non-null int64\n",
      "init_inspec              111854 non-null int64\n",
      "dtypes: datetime64[ns](1), float64(11), int64(6), object(11)\n",
      "memory usage: 24.7+ MB\n"
     ]
    }
   ],
   "source": [
    "inspecs = pd.read_csv('./data/inspec_scores.csv', parse_dates=[DATE])\n",
    "inspecs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do some feature pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the catagorical features. For some reason I couldn't just use the onehot.\n",
    "# i needed to actually add new columns to the DF for each new feature\n",
    "\n",
    "# enc = preprocessing.OneHotEncoder(sparse=False)\n",
    "# for feat in CAT_FEATURES:\n",
    "#     enc.fit(inspecs[feat].unique().reshape(-1, 1))\n",
    "#     inspecs[f'{feat}_enc'] = enc.transform(inspecs[feat].values.reshape(-1, 1)).tolist()\n",
    "\n",
    "for feat in CAT_FEATURES:\n",
    "    try:\n",
    "        new_df = pd.concat([new_df, pd.get_dummies(inspecs[feat])], axis=1)\n",
    "    except NameError:\n",
    "        new_df = pd.DataFrame(index=inspecs.index)\n",
    "        new_df = pd.concat([new_df, pd.get_dummies(inspecs[feat])], axis=1)\n",
    "#     new_df = new_df.drop([feat], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>Bronx</th>\n",
       "      <th>Brooklyn</th>\n",
       "      <th>Manhattan</th>\n",
       "      <th>Queens</th>\n",
       "      <th>Staten Island</th>\n",
       "      <th>10000.0</th>\n",
       "      <th>10001.0</th>\n",
       "      <th>...</th>\n",
       "      <th>11694.0</th>\n",
       "      <th>11697.0</th>\n",
       "      <th>12345.0</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C  Bronx  Brooklyn  Manhattan  Queens  Staten Island  10000.0  \\\n",
       "0  1  0  0      1         0          0       0              0        0   \n",
       "1  1  0  0      1         0          0       0              0        0   \n",
       "2  1  0  0      1         0          0       0              0        0   \n",
       "3  0  1  0      1         0          0       0              0        0   \n",
       "4  1  0  0      1         0          0       0              0        0   \n",
       "\n",
       "   10001.0  ...  11694.0  11697.0  12345.0  Friday  Monday  Saturday  Sunday  \\\n",
       "0        0  ...        0        0        0       0       0         0       0   \n",
       "1        0  ...        0        0        0       1       0         0       0   \n",
       "2        0  ...        0        0        0       0       0         0       0   \n",
       "3        0  ...        0        0        0       0       0         0       0   \n",
       "4        0  ...        0        0        0       0       1         0       0   \n",
       "\n",
       "   Thursday  Tuesday  Wednesday  \n",
       "0         1        0          0  \n",
       "1         0        0          0  \n",
       "2         1        0          0  \n",
       "3         0        1          0  \n",
       "4         0        0          0  \n",
       "\n",
       "[5 rows x 236 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the two frames together\n",
    "\n",
    "FEATURES += new_df.columns.tolist()\n",
    "inspecs = pd.concat([inspecs, new_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmax_3d</th>\n",
       "      <th>time_since_last</th>\n",
       "      <th>past_critical</th>\n",
       "      <th>past_score</th>\n",
       "      <th>dsny_heat_score</th>\n",
       "      <th>dep_heat_score</th>\n",
       "      <th>dohmh_heat_score</th>\n",
       "      <th>is_chain</th>\n",
       "      <th>init_inspec</th>\n",
       "      <th>...</th>\n",
       "      <th>11694.0</th>\n",
       "      <th>11697.0</th>\n",
       "      <th>12345.0</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.406452</td>\n",
       "      <td>0.117716</td>\n",
       "      <td>0.098959</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73</td>\n",
       "      <td>72.333333</td>\n",
       "      <td>358.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.203028</td>\n",
       "      <td>0.074187</td>\n",
       "      <td>0.169137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>56.333333</td>\n",
       "      <td>370.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.160208</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.173178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>76.333333</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.256666</td>\n",
       "      <td>0.399057</td>\n",
       "      <td>0.316888</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.309046</td>\n",
       "      <td>0.031414</td>\n",
       "      <td>0.274051</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tmax    tmax_3d  time_since_last  past_critical  past_score  \\\n",
       "0    92  79.000000              0.0            0.0        12.0   \n",
       "1    73  72.333333            358.0            1.0         7.0   \n",
       "2    73  56.333333            370.0            0.0         5.0   \n",
       "3    77  76.333333             26.0            1.0        14.0   \n",
       "4    67  59.000000            132.0            0.0         6.0   \n",
       "\n",
       "   dsny_heat_score  dep_heat_score  dohmh_heat_score  is_chain  init_inspec  \\\n",
       "0         0.406452        0.117716          0.098959         0            1   \n",
       "1         0.203028        0.074187          0.169137         0            0   \n",
       "2         0.160208        0.027397          0.173178         0            0   \n",
       "3         0.256666        0.399057          0.316888         0            0   \n",
       "4         0.309046        0.031414          0.274051         0            0   \n",
       "\n",
       "   ...  11694.0  11697.0  12345.0  Friday  Monday  Saturday  Sunday  Thursday  \\\n",
       "0  ...        0        0        0       0       0         0       0         1   \n",
       "1  ...        0        0        0       1       0         0       0         0   \n",
       "2  ...        0        0        0       0       0         0       0         1   \n",
       "3  ...        0        0        0       0       0         0       0         0   \n",
       "4  ...        0        0        0       0       1         0       0         0   \n",
       "\n",
       "   Tuesday  Wednesday  \n",
       "0        0          0  \n",
       "1        0          0  \n",
       "2        0          0  \n",
       "3        1          0  \n",
       "4        0          0  \n",
       "\n",
       "[5 rows x 246 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspecs[FEATURES].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspecs.to_csv('./data/inspecs_encoded.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Imbalance\n",
    "\n",
    "We know that we have really imbalanced classes. We will need to resample the two classes to make sure that we can train appropriately. Currently, I am both downsampling all the examples where there is a critical violation or upsampling all of the times when there isn't a critical violation.\n",
    "\n",
    "We could use other fancier methods like SMOTE, but not right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    100369\n",
      "0     11485\n",
      "Name: critical, dtype: int64\n",
      "1    11485\n",
      "0    11485\n",
      "Name: critical, dtype: int64\n",
      "1    100369\n",
      "0    100369\n",
      "Name: critical, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Previously we found that we have really imbalanced classes. Here we'll downsample the majority class to match\n",
    "# the number of the minority class\n",
    "# Separate majority and minority classes\n",
    "df_majority = inspecs[inspecs[TARGET]==1]\n",
    "df_minority = inspecs[inspecs[TARGET]==0]\n",
    "\n",
    "# Downsample Majority Class\n",
    "df_majority_dsampled = resample(df_majority, \n",
    "                                 replace=False, # sample without replacement\n",
    "                                 n_samples=len(df_minority)) # to match minority class\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "df_dsampled = pd.concat([df_minority, df_majority_dsampled])\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=len(df_majority))    # to match majority class\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])    \n",
    "    \n",
    "    \n",
    "# Display new class counts\n",
    "print(inspecs[TARGET].value_counts()) # before\n",
    "print(df_dsampled[TARGET].value_counts()) # downsample\n",
    "print(df_upsampled[TARGET].value_counts()) # upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dsampled.to_csv('./data/inspecs_encoded_dsample.csv', index=False)\n",
    "df_upsampled.to_csv('./data/inspecs_encoded_usample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### START HERE FOR RESTARTS ####\n",
    "\n",
    "# inspecs = pd.read_csv('./data/inspecs_encoded.csv', parse_dates=[DATE])\n",
    "# df_upsampled = pd.read_csv('./data/inspecs_encoded_usample.csv', parse_dates=[DATE])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the training and testing data\n",
    "\n",
    "We are going to train on the balanced data, but we are going to test on the imbalanced data, because that is the what the world actully looks like. \n",
    "\n",
    "\n",
    "I've picked two months toward the middle of 2019, but it can be anything (in 2019)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = select_by_date(df_upsampled, '2018-01-01', '2018-12-31')\n",
    "test = select_by_date(inspecs, '2019-05-01', '2019-06-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65456, 265)\n",
      "(7887, 265)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Models\n",
    "\n",
    "We are gonna build a bunch of them. Mostly, because I am interested in their performance. We can also think about trying to combine models in some fancy-ish way. Like using a interpretable model to do feature ranking and then dumping those features into a less interpretable model (but better?) to make the actual predictions.\n",
    "\n",
    "I am gonna builld a lot of models, because they are easy to do. If they were harder to actually impliment, then I would need to think harder about which models we actually care about... It would be some sort of a decision tree. It is both interpretable and will provide probabilities (what we actually care about) for the individual predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.59      0.25       906\n",
      "           1       0.92      0.60      0.72      6981\n",
      "\n",
      "    accuracy                           0.60      7887\n",
      "   macro avg       0.54      0.59      0.49      7887\n",
      "weighted avg       0.83      0.60      0.67      7887\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boada/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "log_base = LogisticRegression(solver='lbfgs')\n",
    "log_base.fit(train[FEATURES], train[TARGET])\n",
    "predictions = log_base.predict(test[FEATURES])\n",
    "\n",
    "with open('./models/logmodel.pkl', 'wb') as model:\n",
    "    pickle.dump(log_base, model)\n",
    "\n",
    "print(metrics.classification_report(test[TARGET], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.09      0.15       906\n",
      "           1       0.89      0.98      0.93      6981\n",
      "\n",
      "    accuracy                           0.88      7887\n",
      "   macro avg       0.64      0.54      0.54      7887\n",
      "weighted avg       0.83      0.88      0.84      7887\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RF_base = RandomForestClassifier()\n",
    "RF_base.fit(train[FEATURES], train[TARGET])\n",
    "predictions = RF_base.predict(test[FEATURES])\n",
    "\n",
    "with open('./models/RFmodel.pkl', 'wb') as model:\n",
    "    pickle.dump(RF_base, model)\n",
    "\n",
    "print(metrics.classification_report(test[TARGET], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.63      0.28       906\n",
      "           1       0.93      0.64      0.76      6981\n",
      "\n",
      "    accuracy                           0.64      7887\n",
      "   macro avg       0.56      0.63      0.52      7887\n",
      "weighted avg       0.84      0.64      0.70      7887\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GBT_base = GradientBoostingClassifier()\n",
    "GBT_base.fit(train[FEATURES], train[TARGET])\n",
    "predictions = GBT_base.predict(test[FEATURES])\n",
    "\n",
    "with open('./models/GBTmodel.pkl', 'wb') as model:\n",
    "    pickle.dump(GBT_base, model)\n",
    "\n",
    "print(metrics.classification_report(test[TARGET], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.65      0.28       906\n",
      "           1       0.93      0.61      0.74      6981\n",
      "\n",
      "    accuracy                           0.62      7887\n",
      "   macro avg       0.56      0.63      0.51      7887\n",
      "weighted avg       0.85      0.62      0.69      7887\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_base=AdaBoostClassifier()\n",
    "ada_base.fit(train[FEATURES], train[TARGET])\n",
    "predictions = ada_base.predict(test[FEATURES])\n",
    "\n",
    "with open('./models/AdaBmodel.pkl', 'wb') as model:\n",
    "    pickle.dump(ada_base, model)\n",
    "\n",
    "print(metrics.classification_report(test[TARGET], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.63      0.29       906\n",
      "           1       0.93      0.64      0.76      6981\n",
      "\n",
      "    accuracy                           0.64      7887\n",
      "   macro avg       0.56      0.64      0.52      7887\n",
      "weighted avg       0.84      0.64      0.70      7887\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb_base = xgb.XGBClassifier()\n",
    "xgb_base.fit(train[FEATURES], train[TARGET])\n",
    "predictions = xgb_base.predict(test[FEATURES])\n",
    "\n",
    "with open('./models/XGBmodel.pkl', 'wb') as model:\n",
    "    pickle.dump(xgb_base, model)\n",
    "\n",
    "print(metrics.classification_report(test[TARGET], predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural Network\n",
    "\n",
    "Using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52364 samples, validate on 13092 samples\n",
      "Epoch 1/50\n",
      "Epoch 2/50\n",
      "Epoch 3/50\n",
      "Epoch 4/50\n",
      "Epoch 5/50\n",
      "Epoch 6/50\n",
      "Epoch 7/50\n",
      "Epoch 8/50\n",
      "Epoch 9/50\n",
      "Epoch 10/50\n",
      "Epoch 11/50\n",
      "Epoch 12/50\n",
      "Epoch 13/50\n",
      "Epoch 14/50\n",
      "Epoch 15/50\n",
      "Epoch 16/50\n",
      "Epoch 17/50\n",
      "Epoch 18/50\n",
      "Epoch 19/50\n",
      "Epoch 20/50\n",
      "Epoch 21/50\n",
      "Epoch 22/50\n",
      "Epoch 23/50\n",
      "Epoch 24/50\n",
      "Epoch 25/50\n",
      "Epoch 26/50\n",
      "Epoch 27/50\n",
      "Epoch 28/50\n",
      "Epoch 29/50\n",
      "Epoch 30/50\n",
      "Epoch 31/50\n",
      "Epoch 32/50\n",
      "Epoch 33/50\n",
      "Epoch 34/50\n",
      "Epoch 35/50\n",
      "Epoch 36/50\n",
      "Epoch 37/50\n",
      "Epoch 38/50\n",
      "Epoch 39/50\n",
      "Epoch 40/50\n",
      "Epoch 41/50\n",
      "Epoch 42/50\n",
      "Epoch 43/50\n",
      "Epoch 44/50\n",
      "Epoch 45/50\n",
      "Epoch 46/50\n",
      "Epoch 47/50\n",
      "Epoch 48/50\n",
      "Epoch 49/50\n",
      "Epoch 50/50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.49      0.24       906\n",
      "           1       0.91      0.66      0.76      6981\n",
      "\n",
      "    accuracy                           0.64      7887\n",
      "   macro avg       0.53      0.57      0.50      7887\n",
      "weighted avg       0.82      0.64      0.70      7887\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential, layers, models\n",
    "\n",
    "input_shape = train[FEATURES].shape[1]\n",
    "\n",
    "# Instantiation = Initialising the neural network object,it's a sequential model\n",
    "model = models.Sequential()\n",
    "# First hidden layer\n",
    "model.add(layers.Dense(activation=\"relu\", input_dim=input_shape, units=100, kernel_initializer=\"uniform\"))\n",
    "# Second hidden \n",
    "model.add(layers.Dense(activation=\"relu\", units=50, kernel_initializer=\"uniform\"))\n",
    "# Add the Output layer\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\"))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "NN_base = model.fit(train[FEATURES],train[TARGET], epochs=50, batch_size=256, validation_split=0.2, verbose=3)\n",
    "\n",
    "with open('./models/NNmodel.pkl', 'wb') as model:\n",
    "    pickle.dump(NN_base.model, model)\n",
    "\n",
    "predictions = NN_base.model.predict_classes(test[FEATURES])\n",
    "print(metrics.classification_report(test[TARGET], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Ranking\n",
    "\n",
    "Let's see if we can get some better performance by removing low importance features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_since_last\t\t0.12180\n",
      "dep_heat_score\t\t0.09263\n",
      "dsny_heat_score\t\t0.09207\n",
      "dohmh_heat_score\t\t0.09143\n",
      "tmax_3d\t\t0.07534\n",
      "tmax\t\t0.07100\n",
      "past_score\t\t0.06409\n",
      "is_chain\t\t0.01949\n",
      "Wednesday\t\t0.01185\n",
      "Thursday\t\t0.01096\n",
      "Tuesday\t\t0.01091\n",
      "Manhattan\t\t0.01058\n",
      "Monday\t\t0.01033\n",
      "Brooklyn\t\t0.00987\n",
      "past_critical\t\t0.00948\n",
      "Queens\t\t0.00945\n",
      "Friday\t\t0.00777\n",
      "Bronx\t\t0.00688\n",
      "B\t\t0.00546\n",
      "10019.0\t\t0.00497\n",
      "10036.0\t\t0.00457\n",
      "A\t\t0.00453\n",
      "C\t\t0.00447\n",
      "10003.0\t\t0.00447\n",
      "Saturday\t\t0.00439\n",
      "10013.0\t\t0.00410\n",
      "10001.0\t\t0.00399\n",
      "Staten Island\t\t0.00398\n",
      "10022.0\t\t0.00396\n",
      "10017.0\t\t0.00356\n",
      "10011.0\t\t0.00354\n",
      "10016.0\t\t0.00352\n",
      "11217.0\t\t0.00342\n",
      "10014.0\t\t0.00333\n",
      "11201.0\t\t0.00326\n",
      "10018.0\t\t0.00323\n",
      "10012.0\t\t0.00313\n",
      "11372.0\t\t0.00307\n",
      "10002.0\t\t0.00305\n",
      "11220.0\t\t0.00301\n",
      "11215.0\t\t0.00300\n",
      "11368.0\t\t0.00269\n",
      "11101.0\t\t0.00265\n",
      "10009.0\t\t0.00256\n",
      "10010.0\t\t0.00249\n",
      "11354.0\t\t0.00247\n",
      "init_inspec\t\t0.00244\n",
      "11385.0\t\t0.00243\n",
      "10025.0\t\t0.00234\n",
      "11226.0\t\t0.00234\n",
      "11373.0\t\t0.00233\n",
      "11432.0\t\t0.00229\n",
      "11103.0\t\t0.00227\n",
      "11238.0\t\t0.00226\n",
      "11377.0\t\t0.00222\n",
      "11211.0\t\t0.00219\n",
      "10023.0\t\t0.00219\n",
      "10065.0\t\t0.00215\n",
      "11237.0\t\t0.00210\n",
      "10029.0\t\t0.00208\n",
      "11222.0\t\t0.00207\n",
      "10027.0\t\t0.00205\n",
      "10121.0\t\t0.00203\n",
      "11209.0\t\t0.00196\n",
      "11430.0\t\t0.00196\n",
      "11355.0\t\t0.00192\n",
      "10458.0\t\t0.00192\n",
      "10028.0\t\t0.00189\n",
      "10004.0\t\t0.00187\n",
      "10468.0\t\t0.00187\n",
      "11375.0\t\t0.00185\n",
      "11206.0\t\t0.00185\n",
      "11235.0\t\t0.00182\n",
      "10038.0\t\t0.00182\n",
      "11105.0\t\t0.00179\n",
      "11216.0\t\t0.00175\n",
      "11214.0\t\t0.00174\n",
      "10461.0\t\t0.00173\n",
      "10128.0\t\t0.00173\n",
      "11225.0\t\t0.00170\n",
      "10314.0\t\t0.00168\n",
      "11223.0\t\t0.00167\n",
      "10451.0\t\t0.00166\n",
      "10467.0\t\t0.00165\n",
      "11231.0\t\t0.00160\n",
      "10021.0\t\t0.00157\n",
      "10024.0\t\t0.00155\n",
      "11207.0\t\t0.00153\n",
      "11218.0\t\t0.00152\n",
      "10462.0\t\t0.00151\n",
      "10007.0\t\t0.00150\n",
      "11106.0\t\t0.00149\n",
      "11234.0\t\t0.00148\n",
      "11249.0\t\t0.00145\n",
      "11205.0\t\t0.00143\n",
      "11219.0\t\t0.00143\n",
      "10033.0\t\t0.00142\n",
      "11361.0\t\t0.00141\n",
      "10463.0\t\t0.00139\n",
      "11369.0\t\t0.00138\n",
      "11204.0\t\t0.00135\n",
      "10466.0\t\t0.00131\n",
      "11419.0\t\t0.00129\n",
      "11358.0\t\t0.00129\n",
      "11435.0\t\t0.00127\n",
      "11232.0\t\t0.00127\n",
      "11102.0\t\t0.00117\n",
      "10032.0\t\t0.00117\n",
      "10075.0\t\t0.00114\n",
      "11208.0\t\t0.00114\n",
      "11203.0\t\t0.00112\n",
      "10453.0\t\t0.00111\n",
      "11229.0\t\t0.00110\n",
      "11374.0\t\t0.00109\n",
      "11378.0\t\t0.00108\n",
      "10031.0\t\t0.00108\n",
      "11221.0\t\t0.00106\n",
      "11212.0\t\t0.00105\n",
      "10455.0\t\t0.00103\n",
      "11236.0\t\t0.00102\n",
      "11213.0\t\t0.00102\n",
      "10040.0\t\t0.00102\n",
      "10460.0\t\t0.00101\n",
      "11357.0\t\t0.00101\n"
     ]
    }
   ],
   "source": [
    "idx = np.argsort(RF_base.feature_importances_)[::-1]\n",
    "for f, i in zip(np.asarray(FEATURES)[idx], RF_base.feature_importances_[idx]):\n",
    "    if i > 0.001:\n",
    "        print(f'{f}\\t\\t{i:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So according to the RF, the first 26 features are \"important\" and then it's all the zip codes... Let's use the first 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time_since_last', 'dep_heat_score', 'dsny_heat_score', 'dohmh_heat_score', 'tmax_3d', 'tmax', 'past_score', 'is_chain', 'Wednesday', 'Thursday', 'Tuesday', 'Manhattan', 'Monday', 'Brooklyn', 'past_critical', 'Queens', 'Friday', 'Bronx', 'B', '10019.0', '10036.0', 'A', 'C', '10003.0', 'Saturday', '10013.0', '10001.0']\n"
     ]
    }
   ],
   "source": [
    "new_FEATURES = np.asarray(FEATURES)[idx][:27].tolist()\n",
    "print(new_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is some issue with just using them... AH!\n",
    "# I remember... the column headings are floats. So we have to convert them from strings..\n",
    "# seems wonky, but it works... \n",
    "nf = []\n",
    "for f in new_FEATURES:\n",
    "    try:\n",
    "        nf.append(float(f))\n",
    "    except ValueError:\n",
    "        nf.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.08      0.13       906\n",
      "           1       0.89      0.98      0.93      6981\n",
      "\n",
      "    accuracy                           0.88      7887\n",
      "   macro avg       0.63      0.53      0.53      7887\n",
      "weighted avg       0.83      0.88      0.84      7887\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at the RF again... \n",
    "\n",
    "RF_base.fit(train[nf], train[TARGET])\n",
    "predictions = RF_base.predict(test[nf])\n",
    "\n",
    "print(metrics.classification_report(test[TARGET], predictions))\n",
    "\n",
    "\n",
    "### So removing the extra features doesn't acutally help it... Let's look at another one... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.63      0.28       906\n",
      "           1       0.93      0.62      0.75      6981\n",
      "\n",
      "    accuracy                           0.62      7887\n",
      "   macro avg       0.55      0.63      0.51      7887\n",
      "weighted avg       0.84      0.62      0.69      7887\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_base.fit(train[nf], train[TARGET])\n",
    "predictions = xgb_base.predict(test[nf])\n",
    "\n",
    "print(metrics.classification_report(test[TARGET], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Gonna use a search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    max_samples=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=100,\n",
       "                                                    n_jobs...\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [10, 20, 30, 40, 50, 60,\n",
       "                                                         70, 80, 90, 100, 110,\n",
       "                                                         120, 130, 140, 150,\n",
       "                                                         160, 170, 180, 190,\n",
       "                                                         200]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "\n",
    "### Here's a bunch of code I copied from the net ###\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start=10, stop=200, num=20)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]# Create the random grid\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "RF_tuned = RandomizedSearchCV(estimator=RF_base, \n",
    "                               param_distributions=random_grid, \n",
    "                               n_iter=10, \n",
    "                               cv=3, \n",
    "                               verbose=2, \n",
    "                               n_jobs =-1)\n",
    "\n",
    "RF_tuned.fit(train[FEATURES], train[TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 100,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_tuned.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 100,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 5,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 200,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_tuned.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.24      0.27       906\n",
      "           1       0.90      0.93      0.92      6981\n",
      "\n",
      "    accuracy                           0.85      7887\n",
      "   macro avg       0.61      0.59      0.59      7887\n",
      "weighted avg       0.84      0.85      0.84      7887\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = RF_tuned.best_estimator_.predict(test[FEATURES])\n",
    "\n",
    "print(metrics.classification_report(test[TARGET], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaboost doesn't have that many parameters\n",
    "\n",
    "param_grid_ada = {'n_estimators': [30, 50, 70,100, 150],\n",
    "                'learning_rate': [1.0, 0.5, 0.1]}\n",
    "\n",
    "grid_ada_res = GridSearchCV(estimator=ada_base,\n",
    "                     param_grid=param_grid_ada,\n",
    "                     cv=3,\n",
    "                     verbose=2,\n",
    "                         n_jobs=-1)\n",
    "grid_ada_res.fit(train[FEATURES], train[TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_ada_res.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_ada_res.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid_ada_res.best_estimator_.predict(test[FEATURES])\n",
    "\n",
    "print(metrics.classification_report(test[TARGET], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_ada_res.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_ada_res.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_base=AdaBoostClassifier(learning_rate=grid_ada_res.best_params_['learning_rate'],\n",
    "                            n_estimators=grid_ada_res.best_params_['n_estimators'])\n",
    "ada_base.fit(train[FEATURES], train[TARGET])\n",
    "predictions = ada_base.predict(test2[FEATURES])\n",
    "\n",
    "print(metrics.classification_report(test2[TARGET], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start=10, stop=200, num=20)]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [x for x in np.arange(1, 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_child_weight = [0, 1, 2, 3]\n",
    "# Minimum number of samples required at each leaf node\n",
    "learning_rate = [x for x in np.linspace(0.1, 1, num=5)]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]# Create the random grid\n",
    "\n",
    "param_grid_xgb= {\n",
    "    \"learning_rate\": [0.3,0.5,0.7],\n",
    "    'max_depth': [5,6,7],\n",
    "    'min_child_weight': [0,1,3],\n",
    "    'n_estimators': [10,100],\n",
    "}\n",
    "\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_child_weight': min_child_weight,\n",
    "               'learning_rate': learning_rate,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_xgb = RandomizedSearchCV(estimator=xgb.XGBClassifier(),\n",
    "                               param_distributions=random_grid, \n",
    "                               n_iter=10, \n",
    "                               cv=3, \n",
    "                               verbose=2, \n",
    "                               n_jobs =-1)\n",
    "\n",
    "grid_xgb.fit(train[FEATURES], train[TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_xgb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid_xgb.best_estimator_.predict(test[FEATURES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(test[TARGET], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = grid_xgb.best_estimator_\n",
    "\n",
    "idx = np.argsort(clf.feature_importances_)[::-1]\n",
    "\n",
    "for f, i in zip(np.asarray(FEATURES)[idx], clf.feature_importances_[idx]):\n",
    "        print(f, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import RFE\n",
    "\n",
    "# clf = GradientBoostingClassifier(n_estimators=100)\n",
    "# rfe = RFE(estimator=clf, n_features_to_select=None, step=1)\n",
    "# rfe.fit(train[FEATURES], train[TARGET])\n",
    "# print(rfe.support_)\n",
    "# print(rfe.ranking_)\n",
    "\n",
    "# new_FEATURES = np.array(FEATURES)[rfe.support_]\n",
    "# new_FEATURES = new_FEATURES.tolist()\n",
    "\n",
    "# clf = GradientBoostingClassifier(n_estimators=100)\n",
    "# clf = clf.fit(train[nf], train[TARGET])\n",
    "# predictions = clf.predict(test[nf])\n",
    "\n",
    "# print(metrics.classification_report(test[TARGET], predictions))\n",
    "\n",
    "# nf = []\n",
    "# for f in new_FEATURES:\n",
    "#     try:\n",
    "#         nf.append(float(f))\n",
    "#     except ValueError:\n",
    "#         nf.append(f)\n",
    "\n",
    "# # Create the RFE object and rank each pixel\n",
    "# svc = SVC(kernel=\"linear\", C=1)\n",
    "# rfe = RFE(estimator=svc, n_features_to_select=1, step=1)\n",
    "# rfe.fit(train[FEATURES], train[TARGET])\n",
    "\n",
    "# print(rfe.support_)\n",
    "# print(rfe.ranking_)\n",
    "\n",
    "# FEATURES[idx]\n",
    "\n",
    "# from tpot import TPOTClassifier\n",
    "\n",
    "# tpot = TPOTClassifier(verbosity=2, max_time_mins=5, max_eval_time_mins=0.04, population_size=10)\n",
    "\n",
    "# tpot.fit(train[FEATURES], train[TARGET])\n",
    "# tpot.score(test[FEATURES], test[TARGET])\n",
    "# predictions = tpot.predict(test[FEATURES])\n",
    "# print(metrics.classification_report(test[TARGET], predictions))\n",
    "\n",
    "# y_pred_proba = tpot.predict_proba(test[FEATURES])[::,1]\n",
    "# fpr, tpr, _ = metrics.roc_curve(test[TARGET],  y_pred_proba)\n",
    "# auc = metrics.roc_auc_score(test[TARGET], y_pred_proba)\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "# plt.legend(loc=4)\n",
    "\n",
    "# def plt_hist(history):\n",
    "#     acc = history.history['accuracy']\n",
    "#     val_acc = history.history['val_accuracy']\n",
    "#     loss = history.history['loss']\n",
    "#     val_loss = history.history['val_loss']\n",
    "#     epochs = range(len(acc))\n",
    "#     plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "#     plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "#     plt.title('Training and validation accuracy')\n",
    "#     plt.legend()\n",
    "#     plt.figure()\n",
    "#     plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "#     plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "#     plt.title('Training and validation loss')\n",
    "#     plt.legend()\n",
    "\n",
    "# plt_hist(NN_base)\n",
    "\n",
    "# predictions = model.predict_classes(test2[FEATURES])\n",
    "# print(metrics.classification_report(test2[TARGET], predictions))\n",
    "\n",
    "# model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
